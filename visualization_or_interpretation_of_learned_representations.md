| Title                                                                                                                                                         | Rating             |   Average | Link                                       |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------|----------:|:-------------------------------------------|
| On the Joint Interaction of Models, Data, and Features                                                                                                        | [8, 8, 6, 8]       |      7.5  | https://openreview.net/forum?id=ze7DOLi394 |
| Overthinking the Truth: Understanding how Language Models Process False Demonstrations                                                                        | [8, 8, 6]          |      7.33 | https://openreview.net/forum?id=Tigr1kMDZy |
| Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs                                                                  | [10, 8, 8, 3]      |      7.25 | https://openreview.net/forum?id=MO5PiKHELW |
| Explaining Kernel Clustering via Decision Trees                                                                                                               | [6, 8, 6, 8]       |      7    | https://openreview.net/forum?id=FAGtjl7HOw |
| Interpreting CLIP's Image Representation via Text-Based Decomposition                                                                                         | [8, 6, 6, 8]       |      7    | https://openreview.net/forum?id=5Ca9sSzuDp |
| Evaluating the Zero-shot Robustness of Instruction-tuned Language Models                                                                                      | [8, 6, 5, 8]       |      6.75 | https://openreview.net/forum?id=g9diuvxN6D |
| Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Map                                                                               | [8, 8, 5, 6]       |      6.75 | https://openreview.net/forum?id=mYWsyTuiRp |
| FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators                                              | [6, 8, 6]          |      6.67 | https://openreview.net/forum?id=BPb5AhT2Vf |
| Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making                                                                             | [6, 8, 6]          |      6.67 | https://openreview.net/forum?id=k581sTMyPt |
| Path Choice Matters for Clear Attributions in Path Methods                                                                                                    | [6, 6, 8]          |      6.67 | https://openreview.net/forum?id=gzYgsZgwXa |
| GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks                                                                                             | [6, 8, 6, 8, 5]    |      6.6  | https://openreview.net/forum?id=IjMUGuUmBI |
| Meaning Representations from Trajectories in Autoregressive Models                                                                                            | [6, 6, 6, 8]       |      6.5  | https://openreview.net/forum?id=UyGWafcopT |
| Successor Heads: Recurring, Interpretable Attention Heads In The Wild                                                                                         | [8, 6, 6, 6]       |      6.5  | https://openreview.net/forum?id=kvcbV8KQsi |
| Generalized Neural Collapse for a Large Number of Classes                                                                                                     | [6, 6, 8, 6]       |      6.5  | https://openreview.net/forum?id=TmcH09s6pT |
| On the Foundations of Shortcut Learning                                                                                                                       | [6, 6, 6, 8, 6]    |      6.4  | https://openreview.net/forum?id=Tj3xLVuE9f |
| Knowledge Storage and Extraction in Language Models (Part A)                                                                                                  | [8, 6, 5, 8, 5]    |      6.4  | https://openreview.net/forum?id=rVnxymbsOS |
| Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching                                                       | [8, 3, 8]          |      6.33 | https://openreview.net/forum?id=Ebt7JgMHv1 |
| Linearity of Relation Decoding in Transformer Language Models                                                                                                 | [6, 8, 5]          |      6.33 | https://openreview.net/forum?id=w7LU2s14kE |
| Don't trust your eyes: on the (un)reliability of feature visualizations                                                                                       | [6, 6, 5, 8]       |      6.25 | https://openreview.net/forum?id=OZWHYyfPwY |
| Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels                                                                        | [6, 3, 8, 8]       |      6.25 | https://openreview.net/forum?id=4VgBjsOC8k |
| How Large Language Models Implement Chain-of-Thought?                                                                                                         | [6, 3, 6, 10]      |      6.25 | https://openreview.net/forum?id=b2XfOm3RJa |
| MAP IT to Visualize Representations                                                                                                                           | [8, 8, 5, 3]       |      6    | https://openreview.net/forum?id=OKf6JtXtoy |
| Carrying over Algorithm in Transformers                                                                                                                       | [10, 5, 6, 3]      |      6    | https://openreview.net/forum?id=t3gOYtv1xV |
| Circuit Component Reuse Across Tasks in Transformer Language Models                                                                                           | [5, 5, 6, 8]       |      6    | https://openreview.net/forum?id=fpoAYV6Wsk |
| To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets                                                       | [5, 8, 5]          |      6    | https://openreview.net/forum?id=UHjE5v5MB7 |
| Task structure and nonlinearity jointly determine learned representational geometry                                                                           | [5, 8, 6, 5]       |      6    | https://openreview.net/forum?id=k9t8dQ30kU |
| Vulnerable Region Discovery through Diverse Adversarial Examples                                                                                              | [5, 8, 5]          |      6    | https://openreview.net/forum?id=LbkIwjmua3 |
| EventRPG: Event Data Augmentation with Relevance Propagation Guidance                                                                                         | [8, 5, 5]          |      6    | https://openreview.net/forum?id=i7LCsDMcZ4 |
| Emerging Pixel-level Semantic Knowledge in Diffusion Models                                                                                                   | [6, 6, 6, 6]       |      6    | https://openreview.net/forum?id=YqyTXmF8Y2 |
| Defining and extracting generalizable interaction primitives from DNNs                                                                                        | [5, 5, 8]          |      6    | https://openreview.net/forum?id=OCqyFVFNeF |
| Less is More: Fewer Interpretable Region via Submodular Subset Selection                                                                                      | [6, 6, 6, 6]       |      6    | https://openreview.net/forum?id=jKTUlxo5zy |
| $\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation                                                                           | [6, 6, 6, 6]       |      6    | https://openreview.net/forum?id=wg8NPfeMF9 |
| Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks                                                                                | [3, 5, 8, 8]       |      6    | https://openreview.net/forum?id=up6hr4hIQH |
| A simple and interpretable model of grokking modular arithmetic tasks                                                                                         | [5, 5, 6, 8, 5]    |      5.8  | https://openreview.net/forum?id=0ZUKLCxwBo |
| On convex decision regions in deep network representations                                                                                                    | [5, 5, 5, 8]       |      5.75 | https://openreview.net/forum?id=yMMIWHbjWS |
| Language Models Represent Space and Time                                                                                                                      | [8, 6, 3, 6]       |      5.75 | https://openreview.net/forum?id=jE8xbmvFin |
| UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models                                                               | [3, 6, 6, 8]       |      5.75 | https://openreview.net/forum?id=0j9ZDzMPqr |
| Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition                                                                       | [5, 6, 6, 6]       |      5.75 | https://openreview.net/forum?id=U7VW3KBm34 |
| Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark                                                                                 | [3, 6, 6, 8]       |      5.75 | https://openreview.net/forum?id=cObFETcoeW |
| Interpreting the Inner Mechanisms of Large Language Models in Mathematical Addition                                                                           | [6, 6, 5, 6]       |      5.75 | https://openreview.net/forum?id=VpCqrMMGVm |
| Towards Best Practices of Activation Patching in Language Models: Metrics and Methods                                                                         | [6, 6, 5]          |      5.67 | https://openreview.net/forum?id=Hf17y6u9BC |
| Intriguing Properties of Data Attribution on Diffusion Models                                                                                                 | [5, 6, 6]          |      5.67 | https://openreview.net/forum?id=vKViCoKGcB |
| Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking                                                                                     | [6, 6, 5]          |      5.67 | https://openreview.net/forum?id=8sKcAWOf2D |
| Exploring the cloud of feature interaction scores in a Rashomon set                                                                                           | [6, 5, 6]          |      5.67 | https://openreview.net/forum?id=EPNEazJoAg |
| Knowledge Manipulation in Language Models (Part B)                                                                                                            | [8, 6, 3]          |      5.67 | https://openreview.net/forum?id=2iFBWoR7NH |
| Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models                                                                      | [5, 6, 6]          |      5.67 | https://openreview.net/forum?id=gfFVATffPd |
| Dissecting Language Models: Machine Unlearning via Selective Pruning                                                                                          | [6, 6, 5, 5]       |      5.5  | https://openreview.net/forum?id=8SPSIfR2e0 |
| Quantifying the Plausibility of Context Reliance in Neural Machine Translation                                                                                | [5, 8, 3, 6]       |      5.5  | https://openreview.net/forum?id=XTHfNGI3zT |
| Faithful Vision-Language Interpretation via Concept Bottleneck Models                                                                                         | [8, 3, 6, 5]       |      5.5  | https://openreview.net/forum?id=rp0EdI8X4e |
| Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in AI Models                                                                  | [6, 3, 8, 5]       |      5.5  | https://openreview.net/forum?id=3pWSL8My6B |
| Learning to Jointly Understand Visual and Tactile Signals                                                                                                     | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=NtQqIcSbqv |
| Codebook Features: Sparse and Discrete Interpretability for Neural Networks                                                                                   | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=LfhG5znxzR |
| PRIME: Prioritizing Interpretability in Failure Mode Extraction                                                                                               | [3, 5, 8, 6]       |      5.5  | https://openreview.net/forum?id=QrEHs9w5UF |
| Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals                                                                             | [6, 5, 5, 6]       |      5.5  | https://openreview.net/forum?id=UMfcdRIotC |
| Exploring Unified Perspective For Fast Shapley Value Estimation                                                                                               | [8, 3]             |      5.5  | https://openreview.net/forum?id=CNZmaInj9n |
| LLMs Represent Contextual Tasks as Compact Function Vectors                                                                                                   | [5, 5, 6, 6]       |      5.5  | https://openreview.net/forum?id=AwyxtyMwaG |
| Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization                                                                       | [6, 5, 8, 3]       |      5.5  | https://openreview.net/forum?id=SNGXbZtK6Q |
| IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models                                                                               | [5, 6, 6, 5]       |      5.5  | https://openreview.net/forum?id=gG38EBe2S8 |
| Understanding Addition in Transformers                                                                                                                        | [3, 8, 3, 8]       |      5.5  | https://openreview.net/forum?id=rIx1YXVWZb |
| AttributionLab: Faithfulness of Feature Attribution Under Controllable Environments                                                                           | [5, 6, 5, 6]       |      5.5  | https://openreview.net/forum?id=zhINOCrrqI |
| How do Language Models Bind Entities in Context?                                                                                                              | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=zb3b6oKO77 |
| A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis                                                                         | [5, 6, 6, 5]       |      5.5  | https://openreview.net/forum?id=bkdWThqE6q |
| Towards the Characterization of Representations Learned via Capsule-based Network Architectures                                                               | [5, 5, 6]          |      5.33 | https://openreview.net/forum?id=irorVob9Eq |
| Generative Modeling of Individual Behavior at Scale                                                                                                           | [6, 5, 5]          |      5.33 | https://openreview.net/forum?id=pTqmVbBa8R |
| Model guidance via explanations turns image classifiers into segmentation models                                                                              | [5, 8, 3, 5]       |      5.25 | https://openreview.net/forum?id=3b8CgMO5ix |
| Robust multimodal models have outlier features and encode more concepts                                                                                       | [5, 5, 8, 3]       |      5.25 | https://openreview.net/forum?id=7ffJo4vtTY |
| Toward a Mechanistic Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model                                                  | [6, 3, 6, 6]       |      5.25 | https://openreview.net/forum?id=VJEcAnFPqC |
| The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets                                               | [5, 8, 3, 5]       |      5.25 | https://openreview.net/forum?id=CeJEfNKstt |
| Unifying Feature and Cost Aggregation with Transformers for Dense Correspondence                                                                              | [5, 6, 5, 5]       |      5.25 | https://openreview.net/forum?id=fQHb1uZzl7 |
| Interpreting and Controlling Vision Foundation Models via Text Explanations                                                                                   | [3, 8, 5, 5]       |      5.25 | https://openreview.net/forum?id=5iENGLEJKG |
| Rotation Invariant Quantization for Model Compression                                                                                                         | [8, 5, 5, 3]       |      5.25 | https://openreview.net/forum?id=CXjz7p4qha |
| DAME: A Distillation Based Approach For Model-agnostic Local Explainability                                                                                   | [6, 6, 6, 3]       |      5.25 | https://openreview.net/forum?id=EAT7gmyIH2 |
| AttEXplore: Attribution for Explanation with model parameters eXploration                                                                                     | [5, 6, 5, 5]       |      5.25 | https://openreview.net/forum?id=FsVxd9CIlb |
| NPEFF: Non-Negative Per-Example Fisher Factorization                                                                                                          | [3, 6, 5, 6]       |      5    | https://openreview.net/forum?id=gywQnORzJX |
| TeLLMe what you see: Using LLMs to Explain Neurons in Vision Models                                                                                           | [5, 5, 5, 5]       |      5    | https://openreview.net/forum?id=01ep65umEr |
| Copy Suppression: Comprehensively Understanding an Attention Head                                                                                             | [3, 5, 6, 6]       |      5    | https://openreview.net/forum?id=g8oaZRhDcf |
| Interpretable Diffusion via Information Decomposition                                                                                                         | [6, 6, 6, 3, 3, 6] |      5    | https://openreview.net/forum?id=X6tNkN6ate |
| SPADE: Sparsity-Guided Debugging for Deep Neural Networks                                                                                                     | [6, 3, 8, 3]       |      5    | https://openreview.net/forum?id=ffcHGwb4KF |
| Where Does In-context Machine Translation Happen in Large Language Models?                                                                                    | [5, 6, 3, 6]       |      5    | https://openreview.net/forum?id=3i7iNGxw6r |
| How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks                                                                               | [3, 6, 3, 8]       |      5    | https://openreview.net/forum?id=tHHzfZSP6T |
| Explaining grokking through circuit efficiency                                                                                                                | [6, 5, 3, 6]       |      5    | https://openreview.net/forum?id=7Zbg38nA0J |
| How Language Models Learn Context-Free Grammars                                                                                                               | [3, 5, 6, 6]       |      5    | https://openreview.net/forum?id=qnbLGV9oFL |
| Constrained Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability                                                  | [6, 6, 3]          |      5    | https://openreview.net/forum?id=VNyIVrKrqv |
| The Hidden Language of Diffusion Models                                                                                                                       | [6, 3, 6, 5]       |      5    | https://openreview.net/forum?id=awWpHnEJDw |
| Latent Diffusion Counterfactual Explanations                                                                                                                  | [3, 6, 6]          |      5    | https://openreview.net/forum?id=kkpVgxHQ1S |
| Energy-Based Concept Bottleneck Models                                                                                                                        | [5, 5, 6, 3, 6]    |      5    | https://openreview.net/forum?id=I1quoTXZzc |
| Attacking for Inspection and Instruction: Debiasing Self-explaining Text Classification                                                                       | [3, 5, 6, 5, 6]    |      5    | https://openreview.net/forum?id=SdoSUDBWJY |
| Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory                                   | [6, 3, 3, 8]       |      5    | https://openreview.net/forum?id=4bSQ3lsfEV |
| Pushing Boundaries: Mixup's Influence on Neural Collapse                                                                                                      | [5, 5, 5, 5]       |      5    | https://openreview.net/forum?id=jTSKkcbEsj |
| Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields                                                                                        | [5, 6, 6, 3]       |      5    | https://openreview.net/forum?id=w7BwaDHppp |
| Revisiting Long-term Time Series Forecasting: An Investigation on Affine Mapping                                                                              | [5, 3, 6, 6]       |      5    | https://openreview.net/forum?id=T97kxctihq |
| Explaining Emergent In-Context Learning as Kernel Regression                                                                                                  | [5, 3, 5, 6, 5]    |      4.8  | https://openreview.net/forum?id=v9Pguuamfp |
| Sum-of-Parts Models: Faithful Attributions for Groups of Features                                                                                             | [6, 5, 3, 5, 5]    |      4.8  | https://openreview.net/forum?id=dsd04MYKax |
| Estimation of Concept Explanations Should be Uncertainty Aware                                                                                                | [6, 6, 3, 6, 3]    |      4.8  | https://openreview.net/forum?id=WqsYs05Ri7 |
| Explaining Contrastive Models using Exemplars: Explanation, Confidence, and Knowledge Limits                                                                  | [3, 5, 8, 3]       |      4.75 | https://openreview.net/forum?id=Se6aznYMHa |
| Explaining Time Series via Contrastive and Locally Sparse Perturbations                                                                                       | [5, 6, 3, 5]       |      4.75 | https://openreview.net/forum?id=qDdSRaOiyb |
| Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models                                                                            | [5, 5, 6, 3]       |      4.75 | https://openreview.net/forum?id=Rnxam2SRgB |
| It's About Time: Temporal References in Emergent Communication                                                                                                | [6, 5, 3, 5]       |      4.75 | https://openreview.net/forum?id=CupHThqQl3 |
| Coloring Deep CNN Layers with Activation Hue Loss                                                                                                             | [6, 5, 5, 3]       |      4.75 | https://openreview.net/forum?id=6u6GjS0vKZ |
| Feature Accentuation: Explaining 'what' features respond to in natural images                                                                                 | [3, 3, 8, 5]       |      4.75 | https://openreview.net/forum?id=Ufp0DVjRs0 |
| What do vision transformers learn? A visual exploration                                                                                                       | [5, 3, 6, 5]       |      4.75 | https://openreview.net/forum?id=4aJg9e4nvF |
| Neural Rankers for Code Generation via Inter-Cluster Modeling                                                                                                 | [3, 6, 5, 5]       |      4.75 | https://openreview.net/forum?id=fjJcJhIzYx |
| In-Context Learning Dynamics with Random Binary Sequences                                                                                                     | [5, 5, 3, 6]       |      4.75 | https://openreview.net/forum?id=62K7mALO2q |
| Approaching an unknown communication system by latent space exploration and causal inference                                                                  | [8, 3, 3, 5]       |      4.75 | https://openreview.net/forum?id=kz5igjl04W |
| ReX: A Framework for Incorporating Temporal Information in Model-Agnostic Local Explanation Techniques                                                        | [3, 6, 5, 5]       |      4.75 | https://openreview.net/forum?id=n3z5oALWci |
| LMExplainer: A Knowledge-Enhanced Explainer for Language Models                                                                                               | [5, 5, 6, 3]       |      4.75 | https://openreview.net/forum?id=VRJzlm2ecv |
| Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks                                             | [5, 6, 5, 3]       |      4.75 | https://openreview.net/forum?id=L3yJ54gv3H |
| Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning                                                                           | [5, 3, 5, 6]       |      4.75 | https://openreview.net/forum?id=FeqxK6PW79 |
| Probability-dependent gradient decay in large margin softmax                                                                                                  | [6, 3, 5]          |      4.67 | https://openreview.net/forum?id=tyIPw2m3Um |
| HuRef: HUman-REadable Fingerprint  for Large Language Models                                                                                                  | [6, 5, 3]          |      4.67 | https://openreview.net/forum?id=ibggY9ZJ1T |
| From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning                                            | [3, 6, 5]          |      4.67 | https://openreview.net/forum?id=4rCDEEnTvX |
| Language Models Linearly Represent Sentiment                                                                                                                  | [5, 3, 6]          |      4.67 | https://openreview.net/forum?id=iGDWZFc7Ya |
| SHARCS: SHARed Concept Space for\\Explainable Multimodal Learning                                                                                             | [3, 6, 5]          |      4.67 | https://openreview.net/forum?id=A5nLEfjhJW |
| Prototype Generation: Robust Feature Visualisation for Data Independent Interpretability                                                                      | [5, 1, 8]          |      4.67 | https://openreview.net/forum?id=qW9GVa3Caa |
| Toward $\textbf{F}$aithfulness-guided $\textbf{E}$nsemble $\textbf{I}$nterpretation of Neural Network                                                         | [3, 5, 6]          |      4.67 | https://openreview.net/forum?id=L7jtdGhWzT |
| Explaining the Complex Task Reasoning of Large Language Models with Template-Content Structure                                                                | [3, 5, 6]          |      4.67 | https://openreview.net/forum?id=qGaIMO8dqD |
| A qualitative theory of dynamical systems for assessing stability in ResNets                                                                                  | [8, 3, 3]          |      4.67 | https://openreview.net/forum?id=EMVct15bl5 |
| Trust Regions for Explanations via Black-Box Probabilistic Certification                                                                                      | [6, 3, 6, 3, 5]    |      4.6  | https://openreview.net/forum?id=Of2RhzJ8UJ |
| Grokking Tickets: Lottery Tickets Accelerate Grokking                                                                                                         | [6, 6, 5, 3, 3]    |      4.6  | https://openreview.net/forum?id=WSsP7W8tqN |
| Interpretability Illusions in the Generalization of Simplified Models                                                                                         | [5, 6, 3, 6, 3]    |      4.6  | https://openreview.net/forum?id=v675Iyu0ta |
| A Critical Study of What Pre-trained Code Models (do not) Learn                                                                                               | [5, 5, 5, 3]       |      4.5  | https://openreview.net/forum?id=I0wEUVzbNY |
| SynBench: Evaluating Pretrained Representations for Image Classification using Synthetic Data                                                                 | [6, 6, 3, 3]       |      4.5  | https://openreview.net/forum?id=9RLC0J2N9n |
| Perturbed examples reveal invariances shared by language models                                                                                               | [8, 1, 3, 6]       |      4.5  | https://openreview.net/forum?id=YkEW5TabYN |
| How many views does your deep neural network use for prediction?                                                                                              | [5, 5, 3, 5]       |      4.5  | https://openreview.net/forum?id=QLKgDBUXTR |
| Concept Bottleneck Generative Models                                                                                                                          | [6, 6, 3, 3]       |      4.5  | https://openreview.net/forum?id=L9U5MJJleF |
| Iterative Search Attribution for Deep Neural Networks                                                                                                         | [3, 3, 6, 6]       |      4.5  | https://openreview.net/forum?id=qIn2IgMWYg |
| DeepROCK: Error-controlled interaction detection in deep neural networks                                                                                      | [3, 6]             |      4.5  | https://openreview.net/forum?id=WTh6EnJXWQ |
| Uncovering hidden geometry in Transformers via disentangling position and context                                                                             | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=1M0qIxVKf6 |
| CLIP Exhibits Improved Compositional Generalization Through Representation Disentanglement                                                                    | [5, 3, 5]          |      4.33 | https://openreview.net/forum?id=UVSKuh9eK5 |
| Revealing Unintentional Information Leakage in Low-Dimensional Facial Portrait Representations                                                                | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=48CXLrx7K3 |
| Intuitive or Dependent? Investigating LLms’ Robustness to Conflicting Prompts                                                                                 | [3, 5, 5]          |      4.33 | https://openreview.net/forum?id=bjlTHVAkHS |
| Explaining recommendation systems through contrapositive perturbations                                                                                        | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=mavWQw7DnC |
| Unsupervised Feature Learning with Emergent Data-Driven Prototypicality                                                                                       | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=331CmSWDjz |
| What happens when you fine-tuning your model? Mechanistic analysis of procedurally generated tasks.                                                           | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=A0HKeKl4Nl |
| Phase Transitions in Contrastive Learning                                                                                                                     | [3, 5, 5]          |      4.33 | https://openreview.net/forum?id=dAqH7CfHjL |
| Syntactic Representations Enable Interpretable Hierarchical Word Vectors                                                                                      | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=ZmbCZw81xf |
| Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models                                                      | [5, 6, 3, 3]       |      4.25 | https://openreview.net/forum?id=YKzGrt3m2g |
| MultiContrievers: Analysis of Dense Retrieval Representations                                                                                                 | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=JWHf7lg8zM |
| Arithmetic with Language Models: from Memorization to Computation                                                                                             | [3, 3, 6, 5]       |      4.25 | https://openreview.net/forum?id=YxzEPTH4Ny |
| Conditional MAE: An Empirical Study of Multiple Masking in Masked Autoencoder                                                                                 | [6, 5, 3, 3]       |      4.25 | https://openreview.net/forum?id=JfcLYCqOkQ |
| Deep Network Partition Density Exhibits Double Descent                                                                                                        | [3, 5, 3, 6]       |      4.25 | https://openreview.net/forum?id=cQgjz0mf0r |
| Rectifying Group Irregularities in Explanations for Distribution Shift                                                                                        | [6, 1, 5, 5]       |      4.25 | https://openreview.net/forum?id=1qzUPE5QDZ |
| Head Information Bottleneck: An Evaluation Method for Transformer Head Contributions in Speech Task                                                           | [3, 8, 3, 3]       |      4.25 | https://openreview.net/forum?id=WjYNFZEjc7 |
| Cross-modality Interpretable image classification via Concept Decomposition Vector of Visual Language Models                                                  | [1, 5, 5, 6]       |      4.25 | https://openreview.net/forum?id=pNgY6ODeMp |
| Uncovering Causal Variables in Transformers Using Circuit Probing                                                                                             | [5, 1, 6, 3, 6]    |      4.2  | https://openreview.net/forum?id=sZq3lDDETp |
| A Unified Concept-Based System for Local, Global, and Misclassification Explanations                                                                          | [6, 5, 3, 3, 3]    |      4    | https://openreview.net/forum?id=UqZecMwLTo |
| PEACH: Pretrained-embedding Explanation Across Contextual and Hierarchical Structure                                                                          | [3, 3, 6]          |      4    | https://openreview.net/forum?id=J562Q8Hjut |
| Neuron to Graph: Interpreting Language Model Neurons at Scale                                                                                                 | [5, 3, 1, 5, 6]    |      4    | https://openreview.net/forum?id=JBLHIR8kBZ |
| On the Generalization of Gradient-based Neural Network Interpretations                                                                                        | [3, 6, 3]          |      4    | https://openreview.net/forum?id=EwAGztBkJ6 |
| Deep concept removal                                                                                                                                          | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=veIzQxZUhF |
| A Geometric Analysis of Multi-label Learning under Pick-all-label Loss via Neural Collapse                                                                    | [3, 6, 3]          |      4    | https://openreview.net/forum?id=nYqUmSYoHi |
| What does GPT store in its MLP weights? A case study of long-range dependencies                                                                               | [3, 6, 3]          |      4    | https://openreview.net/forum?id=nUGFpDCu3W |
| On the Hyperparameter Loss Landscapes of Machine Learning Algorithms                                                                                          | [5, 3, 5, 3]       |      4    | https://openreview.net/forum?id=PlZIXgfWPH |
| Enhancing Neural Network Transparency through Representation Analysis                                                                                         | [3, 6, 3]          |      4    | https://openreview.net/forum?id=aCgybhcZFi |
| Personas as a way to Model Truthfulness in Language Models                                                                                                    | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=rKMQhP6iAv |
| Taming AI Bots: Controllability of Neural States in Large Language Models                                                                                     | [5, 5, 1, 5]       |      4    | https://openreview.net/forum?id=X2gjYmy77l |
| Identifying Interpretable Features in Convolutional Neural Networks                                                                                           | [5, 1, 5, 5]       |      4    | https://openreview.net/forum?id=FVItLat5ii |
| Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation                                                                           | [3, 5, 5, 3]       |      4    | https://openreview.net/forum?id=PKsTHJXn4d |
| Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts                                                                                    | [5, 5, 3, 3]       |      4    | https://openreview.net/forum?id=wrqAn3AJA1 |
| Normalized Space Alignment: A Versatile Metric for Representation Space Discrepancy Minimization                                                              | [3, 3, 3, 6]       |      3.75 | https://openreview.net/forum?id=5HGPR6fg2S |
| A Mechanism for Solving Relational Tasks in Transformer Language Models                                                                                       | [6, 1, 5, 3]       |      3.75 | https://openreview.net/forum?id=ZmzLrl8nTa |
| On Synthetic Data and Iterative Magnitude Pruning: a Linear Mode Connectivity Study                                                                           | [6, 1, 3, 5]       |      3.75 | https://openreview.net/forum?id=5451cIQdWp |
| Hierarchical Approach to Explaining Poisoned AI Models                                                                                                        | [6, 3, 3, 3]       |      3.75 | https://openreview.net/forum?id=rtCROgWC2o |
| Episodic Memory Theory for the Mechanistic Interpretation of Recurrent Neural Networks                                                                        | [3, 5, 6, 1]       |      3.75 | https://openreview.net/forum?id=HEcbGXzIHK |
| Balancing Information Preservation and Computational Efficiency: L2 Normalization and Geodesic Distance in Manifold Learning                                  | [3, 5, 3]          |      3.67 | https://openreview.net/forum?id=2Kf1AIdeyt |
| Latent Concept-based Explanation of NLP Models                                                                                                                | [3, 3, 5]          |      3.67 | https://openreview.net/forum?id=TdyfmCM8iR |
| Interpretable Latent Distributions Using Space-Filling Curves                                                                                                 | [5, 3, 3]          |      3.67 | https://openreview.net/forum?id=RC2h1WQvPo |
| In-Context Learning in Large Language Models: A Neuroscience-inspired Analysis of Representations                                                             | [3, 3, 5, 3]       |      3.5  | https://openreview.net/forum?id=UEdS2lIgfY |
| Discovering Knowledge-Critical Subnetworks in Neural Language Models                                                                                          | [5, 3, 3, 3]       |      3.5  | https://openreview.net/forum?id=Mkdwvl3Y8L |
| Traveling Words: A Geometric Interpretation of Transformers                                                                                                   | [3, 3, 3, 5]       |      3.5  | https://openreview.net/forum?id=cSSHiLnjsJ |
| Measuring Feature Sparsity in Language Models                                                                                                                 | [5, 3, 3, 3]       |      3.5  | https://openreview.net/forum?id=SznHfMwmjG |
| Stop overkilling simple tasks with black-box models, use more transparent models instead                                                                      | [3, 5, 3, 3]       |      3.5  | https://openreview.net/forum?id=zqVvdn0NQM |
| An Entropic Risk Measure for Robust Counterfactual Explanations                                                                                               | [3, 3, 3, 5]       |      3.5  | https://openreview.net/forum?id=uFHDOSfuGS |
| Integrated Model Explanations by Independent and Collaborative Feature Influence via Linear-Nonlinear Perspectives.                                           | [3, 3, 3, 3, 5]    |      3.4  | https://openreview.net/forum?id=v5lmhckxlu |
| SEMANTIC RHEOLOGY: THE FLOW OF IDEAS IN LANGUAGE MODELS                                                                                                       | [3, 3, 1, 6]       |      3.25 | https://openreview.net/forum?id=vrjDNgAfp4 |
| A counterfactual-based approach to prevent crowding in intelligent subway systems                                                                             | [6, 1, 3, 3]       |      3.25 | https://openreview.net/forum?id=wOMy6J8epf |
| Divergence at the Interpolation Threshold: Identifying, Interpreting & Ablating the Sources of a Deep Learning Puzzle                                         | [1, 3, 3, 6]       |      3.25 | https://openreview.net/forum?id=Uhxtq4nCzS |
| Towards Understanding The Winner-Take-Most Behavior Of Neural Network Representations                                                                         | [6, 1, 3, 3]       |      3.25 | https://openreview.net/forum?id=sJslLVsYNo |
| M-IDAS: MULTI-MODAL INTRUSION DETECTION AND ANALYTIC SYSTEM                                                                                                   | [3, 3, 3]          |      3    | https://openreview.net/forum?id=rTdbRWWdR5 |
| Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders                                                                            | [3, 3, 3]          |      3    | https://openreview.net/forum?id=bIb1xhSCVY |
| Brain-inspired Geometry Constrain on Represention for Compositional Generalization                                                                            | [3, 5, 3, 1]       |      3    | https://openreview.net/forum?id=RIaIpdUCPb |
| Towards Meta-Models for Automated Interpretability                                                                                                            | [5, 3, 1]          |      3    | https://openreview.net/forum?id=fM1ETm3ssl |
| CLAM: Class-wise Layer-wise Attribute Model for Explaining Neural Networks                                                                                    | [3, 3, 3, 3]       |      3    | https://openreview.net/forum?id=WIxiwMROqV |
| MapSelect: Sparse & Interpretable Graph Attention Networks                                                                                                    | [3, 3, 3, 3]       |      3    | https://openreview.net/forum?id=2bF381xEke |
| On the Dynamics of Learning Time-Aware Behavior with RNNs                                                                                                     | [3, 3, 3, 3]       |      3    | https://openreview.net/forum?id=7eYmijcuqO |
| Visual Analysis of the Bumpiness and Ruggedness of Residual Neural Network Landscapes                                                                         | [3, 3, 3]          |      3    | https://openreview.net/forum?id=CgBhR1NSLM |
| Interpretable word-level context-based sentiment analysis                                                                                                     | [3, 3, 3]          |      3    | https://openreview.net/forum?id=Pj52xO5ysY |
| Biased Binary Attribute Classifiers Ignore the Majority Classes                                                                                               | [3, 3, 3, 3]       |      3    | https://openreview.net/forum?id=gmHtBH8Fnp |
| Understanding Deep Neural Networks as Dynamical Systems: Insights into Training and Fine-tuning                                                               | [3, 3, 1, 5, 1]    |      2.6  | https://openreview.net/forum?id=4YK1e3Ehdy |
| Patch Ranking Map: Explaining Relations among Top-Ranked Patches, Top-Ranked Features and Decisions of Convolutional Neural Networks for Image Classification | [1, 1, 3, 5]       |      2.5  | https://openreview.net/forum?id=FTSUDBM6lu |
| Data Descriptions from Large Language Models with Influence Estimation                                                                                        | [3, 1, 3, 3]       |      2.5  | https://openreview.net/forum?id=EfSOT1QUlw |
| Search and Retrieval in Semantic-Structural Representations of Novel Malware                                                                                  | [3, 1, 3, 3]       |      2.5  | https://openreview.net/forum?id=51cjeYcXjs |
| Metanetwork: A novel approach to interpreting ANNs                                                                                                            | [1, 3, 3, 3]       |      2.5  | https://openreview.net/forum?id=9L9j5bQPIY |
| QualEval: Qualitative Evaluation for Model Improvement                                                                                                        | [3, 1, 3]          |      2.33 | https://openreview.net/forum?id=8ayoKVFmxp |