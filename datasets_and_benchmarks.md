| Title                                                                                                                                    | Rating             |   Average | Link                                       |
|:-----------------------------------------------------------------------------------------------------------------------------------------|:-------------------|----------:|:-------------------------------------------|
| BooookScore: A systematic exploration of book-length summarization in the era of LLMs                                                    | [8, 8, 10, 8]      |      8.5  | https://openreview.net/forum?id=7Ttk3RzDeu |
| RealChat-1M: A Large-Scale Real-World LLM Conversation Dataset                                                                           | [8, 8, 8, 6]       |      7.5  | https://openreview.net/forum?id=BOfDKxfwt0 |
| COLLIE: Systematic Construction of Constrained Text Generation Tasks                                                                     | [10, 6, 8, 6]      |      7.5  | https://openreview.net/forum?id=kxgSlyirUZ |
| Evaluating Large Language Models at Evaluating Instruction Following                                                                     | [8, 6, 8]          |      7.33 | https://openreview.net/forum?id=tr0KidwPLc |
| A Benchmark for Learning to Translate a New Language from One Grammar Book                                                               | [8, 8, 5]          |      7    | https://openreview.net/forum?id=tbVWug9f2h |
| Benchmarking Algorithms for Federated Domain Generalization                                                                              | [6, 8]             |      7    | https://openreview.net/forum?id=wprSv7ichW |
| Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy                 | [5, 8, 8]          |      7    | https://openreview.net/forum?id=EXitynZhYn |
| CivRealm: A Learning and Reasoning Odyssey for Decision-Making Agents                                                                    | [8, 8, 5]          |      7    | https://openreview.net/forum?id=UBVNwD3hPN |
| PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization                                                       | [8, 8, 5]          |      7    | https://openreview.net/forum?id=5Nn2BLV7SB |
| What's In My Big Data?                                                                                                                   | [5, 8, 5, 10]      |      7    | https://openreview.net/forum?id=RvfPnOkPV4 |
| MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts                                                     | [5, 6, 8, 8]       |      6.75 | https://openreview.net/forum?id=KUNzEQMWU7 |
| GAIA: a benchmark for General AI Assistants                                                                                              | [3, 8, 8, 8]       |      6.75 | https://openreview.net/forum?id=fibxvahvs3 |
| Zero and Few-shot Semantic Parsing with Ambiguous Inputs                                                                                 | [8, 6, 5, 8]       |      6.75 | https://openreview.net/forum?id=qL9gogRepu |
| Learning Performance-Improving Code Edits                                                                                                | [8, 8, 3, 8]       |      6.75 | https://openreview.net/forum?id=ix7rLVHXyY |
| Mol-Instructions - A Large-Scale Biomolecular Instruction Dataset for Large Language Models                                              | [5, 8, 8, 6]       |      6.75 | https://openreview.net/forum?id=Tlsdsb6l9n |
| KoLA: Carefully Benchmarking World Knowledge of Large Language Models                                                                    | [8, 8, 6, 5]       |      6.75 | https://openreview.net/forum?id=AqN23oqraW |
| FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets                                                              | [6, 6, 8]          |      6.67 | https://openreview.net/forum?id=CYmF38ysDa |
| Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision                                                           | [6, 8, 6]          |      6.67 | https://openreview.net/forum?id=0V5TVt9bk0 |
| MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data                                                                           | [6, 6, 8]          |      6.67 | https://openreview.net/forum?id=8xliOUg9EW |
| Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots                                                                                | [6, 6, 8]          |      6.67 | https://openreview.net/forum?id=4znwzG92CE |
| Unveiling the Pitfalls of Knowledge Editing for Large Language Models                                                                    | [8, 8, 5, 5]       |      6.5  | https://openreview.net/forum?id=fNktD3ib16 |
| DyVal: Graph-informed Dynamic Evaluation of Large Language Models                                                                        | [6, 6, 6, 8]       |      6.5  | https://openreview.net/forum?id=gjfOL9z5Xr |
| SmartPlay : A Benchmark for LLMs as Intelligent Agents                                                                                   | [8, 5, 5, 8]       |      6.5  | https://openreview.net/forum?id=S2oTVrlcp3 |
| Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning                                                       | [5, 5, 8, 8]       |      6.5  | https://openreview.net/forum?id=J44HfH4JCg |
| CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis                                                   | [8, 6, 6, 6]       |      6.5  | https://openreview.net/forum?id=pw2ssoOTpo |
| Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation                                                         | [5, 8, 5, 8]       |      6.5  | https://openreview.net/forum?id=ycF7mKfVGO |
| MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation                                                              | [8, 5, 6]          |      6.33 | https://openreview.net/forum?id=DiWRG9JTWZ |
| SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series                                                      | [3, 8, 8]          |      6.33 | https://openreview.net/forum?id=s9z0HzWJJp |
| Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations                                                  | [8, 6, 5]          |      6.33 | https://openreview.net/forum?id=6pPYRXKPpw |
| WebArena: A Realistic Web Environment for Building Autonomous Agents                                                                     | [8, 6, 5]          |      6.33 | https://openreview.net/forum?id=oKn9c6ytLx |
| Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks                                                                     | [6, 5, 8]          |      6.33 | https://openreview.net/forum?id=NSDszJ2uIV |
| CMMLU: Measuring massive multitask language understanding in Chinese                                                                     | [8, 6, 5]          |      6.33 | https://openreview.net/forum?id=ck4SG9lnrQ |
| FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation                                                              | [6, 5, 8]          |      6.33 | https://openreview.net/forum?id=q38SZkUmUh |
| Welfare Diplomacy: Benchmarking Language Model Cooperation                                                                               | [8, 5, 6]          |      6.33 | https://openreview.net/forum?id=AKJLnDgzkm |
| SpaCE: The Spatial Confounding Environment                                                                                               | [6, 5, 8]          |      6.33 | https://openreview.net/forum?id=D9rJdtmIG6 |
| Alice Benchmarks: Connecting Real World Object Re-Identification with the Synthetic                                                      | [6, 8, 5, 6]       |      6.25 | https://openreview.net/forum?id=vkkHqoerLV |
| Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations                                                 | [6, 6, 8, 5]       |      6.25 | https://openreview.net/forum?id=uLOFyiruin |
| Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community                    | [6, 6, 8, 5]       |      6.25 | https://openreview.net/forum?id=tjn2YZSHUv |
| I-PHYRE: Interactive Physical Reasoning                                                                                                  | [6, 8, 6, 5]       |      6.25 | https://openreview.net/forum?id=1bbPQShCT2 |
| ADoPD: A Large-Scale Document Page Decomposition Dataset                                                                                 | [5, 6, 6, 8]       |      6.25 | https://openreview.net/forum?id=x1ptaXpOYa |
| BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge                                             | [8, 6, 6, 5]       |      6.25 | https://openreview.net/forum?id=JbOsMrwjZ3 |
| MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback                                                         | [6, 8, 6, 5]       |      6.25 | https://openreview.net/forum?id=jp3gWrMuIZ |
| EQA-MX: Embodied Question Answering using Multimodal Expression                                                                          | [8, 3, 6, 8]       |      6.25 | https://openreview.net/forum?id=7gUrYE50Rb |
| Compressing LLMs: The Truth is Rarely Pure and Never Simple                                                                              | [8, 3, 8, 6]       |      6.25 | https://openreview.net/forum?id=B9klVS7Ddk |
| (InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild                                                                               | [8, 6, 6, 5]       |      6.25 | https://openreview.net/forum?id=Bl8u7ZRlbM |
| SWE-bench: Can Language Models Resolve Real-world Github Issues?                                                                         | [6, 8, 6, 5]       |      6.25 | https://openreview.net/forum?id=VTF8yNQM66 |
| HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments                                                          | [5, 6, 6, 8]       |      6.25 | https://openreview.net/forum?id=n6mLhaBahJ |
| Data Filtering Networks                                                                                                                  | [8, 8, 3, 6]       |      6.25 | https://openreview.net/forum?id=KAk6ngZ09F |
| UltraFeedback: Boosting Language Models with High-quality Feedback                                                                       | [6, 6, 5, 8]       |      6.25 | https://openreview.net/forum?id=pNkOx3IVWI |
| Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX                                                          | [6, 6, 8, 5]       |      6.25 | https://openreview.net/forum?id=C4CxQmp9wc |
| KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval                                                              | [5, 6, 6, 8]       |      6.25 | https://openreview.net/forum?id=b3kDP3IytM |
| Benchmarking Cognitive Biases in Large Language Models as Evaluators                                                                     | [5, 6, 8, 6]       |      6.25 | https://openreview.net/forum?id=TTEwosByrg |
| How Well Do Supervised Models Transfer to 3D Image Segmentation?                                                                         | [8, 6, 3, 8, 6]    |      6.2  | https://openreview.net/forum?id=AhizIPytk4 |
| SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models                                         | [6, 6, 5, 8, 6]    |      6.2  | https://openreview.net/forum?id=u6jbcaCHqO |
| L-Eval: Instituting Standardized Evaluation for Long Context Language Models                                                             | [5, 8, 5, 6]       |      6    | https://openreview.net/forum?id=eUAr4HwU0X |
| RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems                                                                    | [5, 8, 5]          |      6    | https://openreview.net/forum?id=pPjZIOuQuF |
| Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World                                                    | [6, 5, 5, 8]       |      6    | https://openreview.net/forum?id=hWS4MueyzC |
| Skill-Mix: a Flexible and Expandable Family of Evaluations for AI Models                                                                 | [5, 8, 5]          |      6    | https://openreview.net/forum?id=Jf5gplvglq |
| MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations                | [6, 6, 6, 6]       |      6    | https://openreview.net/forum?id=nY9nITZQjc |
| Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks                                     | [6, 8, 5, 5]       |      6    | https://openreview.net/forum?id=mzxKLZNbrQ |
| InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation                                                  | [5, 6, 8, 5]       |      6    | https://openreview.net/forum?id=MLBdiWu4Fw |
| ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation                                         | [8, 3, 5, 8]       |      6    | https://openreview.net/forum?id=yV6fD7LYkF |
| Abstractive Summarization through the PRISM of Decoding Strategies                                                                       | [8, 5, 6, 5]       |      6    | https://openreview.net/forum?id=A6juYCULJO |
| ContextRef: Evaluating Referenceless Metrics for Image Description Generation                                                            | [6, 6, 6]          |      6    | https://openreview.net/forum?id=j0ZvKSNZiP |
| Dissecting sample hardness: Fine-grained analysis of Hardness Characterization Methods                                                   | [8, 1, 8, 5, 8]    |      6    | https://openreview.net/forum?id=icTZCUbtD6 |
| AgentBench: Evaluating LLMs as Agents                                                                                                    | [3, 8, 6, 8, 5]    |      6    | https://openreview.net/forum?id=zAdUB0aCTQ |
| GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks                                            | [8, 5, 5]          |      6    | https://openreview.net/forum?id=cUSNs8nGaV |
| FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods                                                                  | [5, 8, 3, 8]       |      6    | https://openreview.net/forum?id=TzAJbTClAz |
| Robustness of Deep Learning for Accelerated MRI: Benefits of Diverse Training Data                                                       | [6, 8, 10, 3, 3]   |      6    | https://openreview.net/forum?id=KJYIgEteHX |
| ImagenHub: Standardizing the evaluation of conditional image generation models                                                           | [5, 8, 6, 5]       |      6    | https://openreview.net/forum?id=OuV9ZrkQlc |
| LATEC — A benchmark for large-scale attribution & attention evaluation in computer vision                                                | [8, 5, 8, 6, 3]    |      6    | https://openreview.net/forum?id=tQYsKBTTaV |
| Can Large Language Models Infer Causation from Correlation?                                                                              | [6, 6, 6]          |      6    | https://openreview.net/forum?id=vqIH0ObdqL |
| ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models                               | [3, 8, 6, 6]       |      5.75 | https://openreview.net/forum?id=ClqyY6Bvb7 |
| Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases                                                                   | [5, 8, 5, 5]       |      5.75 | https://openreview.net/forum?id=W0zgCR6FIE |
| CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models                                                            | [3, 8, 6, 6]       |      5.75 | https://openreview.net/forum?id=86NGO8qeWs |
| OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift                                               | [6, 6, 5, 6]       |      5.75 | https://openreview.net/forum?id=RnYd44LR2v |
| ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations                                                   | [5, 5, 5, 8]       |      5.75 | https://openreview.net/forum?id=mBzsKsrXf9 |
| TiC-CLIP: Continual Training of CLIP Models                                                                                              | [6, 6, 5, 6]       |      5.75 | https://openreview.net/forum?id=TLADT8Wrhn |
| SSCBench: Monocular 3D Semantic Scene Completion Benchmark in Street Views                                                               | [5, 5, 8, 5]       |      5.75 | https://openreview.net/forum?id=8fJEOri51F |
| MUBen: Benchmarking the Uncertainty of Molecular Representation Models                                                                   | [5, 5, 5, 8]       |      5.75 | https://openreview.net/forum?id=UIGAtKp8nW |
| To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination                                                        | [5, 6, 6, 6]       |      5.75 | https://openreview.net/forum?id=m2NVG4Htxs |
| SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark                                                        | [6, 6, 3, 8]       |      5.75 | https://openreview.net/forum?id=L2kbdthX5M |
| CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery                                                     | [5, 6, 6, 6]       |      5.75 | https://openreview.net/forum?id=iad1yyyGme |
| Measuring Vision-Language STEM Skills of Neural Models                                                                                   | [5, 6, 6]          |      5.67 | https://openreview.net/forum?id=spvaV5LELF |
| GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts                                                                | [6, 3, 8]          |      5.67 | https://openreview.net/forum?id=LixGd92Wri |
| SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents                                                               | [3, 6, 8]          |      5.67 | https://openreview.net/forum?id=mM7VurbA4r |
| VFLAIR: A Research Library and Benchmark for Vertical Federated Learning                                                                 | [6, 3, 8]          |      5.67 | https://openreview.net/forum?id=sqRgz88TM3 |
| ETGraph: A Pioneering Dataset Bridging Ethereum and Twitter                                                                              | [6, 5, 6]          |      5.67 | https://openreview.net/forum?id=juE0rWGCJW |
| TRAM: Benchmarking Temporal Reasoning for Large Language Models                                                                          | [6, 5, 8, 6, 3]    |      5.6  | https://openreview.net/forum?id=EJvFFedM2I |
| A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines                                             | [3, 8, 8, 3]       |      5.5  | https://openreview.net/forum?id=qhkEOCcVX9 |
| FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback                                                   | [6, 5, 5, 6]       |      5.5  | https://openreview.net/forum?id=7pVIFJW2Hp |
| ARB: Advanced Reasoning Benchmark for Large Language Models                                                                              | [5, 5, 6, 6]       |      5.5  | https://openreview.net/forum?id=gsZAtAdzkY |
| Meta-Referential Games to Learn Compositional Learning Behaviours                                                                        | [5, 5, 6, 6]       |      5.5  | https://openreview.net/forum?id=17BA0Tl2Id |
| Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data                                          | [5, 6, 5, 6]       |      5.5  | https://openreview.net/forum?id=PCXvcULwiI |
| EasyTPP: Towards Open Benchmarking Temporal Point Processes                                                                              | [10, 3, 3, 6]      |      5.5  | https://openreview.net/forum?id=PJwAkg0z7h |
| MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use                                                                       | [5, 8, 6, 3]       |      5.5  | https://openreview.net/forum?id=R0c2qtalgG |
| Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics                                                      | [6, 8, 3, 5]       |      5.5  | https://openreview.net/forum?id=RLhS1TrjK3 |
| MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following                                                          | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=1vrS1zwekw |
| Towards Fair Graph Anomaly Detection: Problem, New Datasets, and Evaluation                                                              | [3, 5, 6, 8]       |      5.5  | https://openreview.net/forum?id=3cE6NKYy8x |
| ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews                                                               | [3, 8, 3, 8]       |      5.5  | https://openreview.net/forum?id=Zr96FfaUGR |
| ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms                                                                | [5, 6, 5, 6]       |      5.5  | https://openreview.net/forum?id=VTYg5ykEGS |
| Rethinking the Effectiveness of Graph Classification Datasets in Benchmarks for Assessing GNNs                                           | [3, 6, 8, 5]       |      5.5  | https://openreview.net/forum?id=om5z1n0mXA |
| Eye Fairness: A Large-Scale 3D Imaging Dataset for Equitable Eye Diseases Screening and Fair Identity Scaling                            | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=Lv9KZ5qCSG |
| OWL: A Large Language Model for IT Operations                                                                                            | [6, 6, 5, 5]       |      5.5  | https://openreview.net/forum?id=SZOQ9RKYJu |
| Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace                                          | [6, 3, 8, 5]       |      5.5  | https://openreview.net/forum?id=xC8xh2RSs2 |
| TaskBench: Benchmarking Large Language Models for Task Automation                                                                        | [8, 6, 5, 3]       |      5.5  | https://openreview.net/forum?id=70xhiS0AQS |
| ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models                                              | [6, 6, 5, 5]       |      5.5  | https://openreview.net/forum?id=liuqDwmbQJ |
| VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks                                           | [5, 5, 6, 6]       |      5.5  | https://openreview.net/forum?id=glwwbaeKm2 |
| Editing Personality for Large Language Models                                                                                            | [3, 6, 5, 8]       |      5.5  | https://openreview.net/forum?id=cxt2Auexc3 |
| InstructDET: Diversifying Referring Object Detection with Generalized Instructions                                                       | [6, 5, 6, 5]       |      5.5  | https://openreview.net/forum?id=hss35aoQ1Y |
| LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models                                          | [5, 6, 5, 5, 6]    |      5.4  | https://openreview.net/forum?id=71kocBuhNO |
| Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML                                                             | [5, 6, 3, 8, 5]    |      5.4  | https://openreview.net/forum?id=ox2ATRM90I |
| NLPBench: Evaluating Large Language Models on Solving NLP Problems                                                                       | [6, 5, 5]          |      5.33 | https://openreview.net/forum?id=fpYIlzOpIA |
| Evaluating Language Models Through Negotiations                                                                                          | [8, 3, 5]          |      5.33 | https://openreview.net/forum?id=3ZqKxMHcAg |
| Evaluating Hallucinations in Chinese Large Language Models                                                                               | [6, 5, 5]          |      5.33 | https://openreview.net/forum?id=1AXvGjfF0V |
| OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text                                                                       | [6, 5, 5]          |      5.33 | https://openreview.net/forum?id=jKHmjlpViu |
| Robust NAS benchmark under adversarial training: assessment, theory, and beyond                                                          | [5, 5, 6]          |      5.33 | https://openreview.net/forum?id=cdUpf6t6LZ |
| Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models                                                    | [8, 3, 5]          |      5.33 | https://openreview.net/forum?id=kZEXgtMNNo |
| GlycoNMR: A Carbohydrate-Specific NMR Chemical Shift Dataset for Machine Learning Research                                               | [5, 6, 5]          |      5.33 | https://openreview.net/forum?id=SmZD7yxpPC |
| Benchmarking Large Language Models as AI Research Agents                                                                                 | [10, 3, 5, 3]      |      5.25 | https://openreview.net/forum?id=N9wD4RFWY0 |
| The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs                      | [8, 3, 5, 5]       |      5.25 | https://openreview.net/forum?id=PfrpYGKGPL |
| Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection                                             | [5, 6, 5, 5]       |      5.25 | https://openreview.net/forum?id=peZbJlOVAN |
| NanoLM: An Affordable LLM Study Benchmark via Accurate Loss Prediction Across Scales                                                     | [5, 5, 6, 5]       |      5.25 | https://openreview.net/forum?id=mao3y822aM |
| A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization                                                        | [5, 6, 5, 5]       |      5.25 | https://openreview.net/forum?id=E6EbeJR20o |
| CUS3D: A New Comprehensive Urban-Scale Semantic Segmentation 3D Benchmark Dataset                                                        | [6, 5, 5, 5]       |      5.25 | https://openreview.net/forum?id=kRdcwzEL5J |
| LaDe: The First Comprehensive Last-mile Express Dataset from Industry                                                                    | [5, 3, 5, 8]       |      5.25 | https://openreview.net/forum?id=pTU2X9mUBe |
| OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification                                                                     | [6, 5, 5, 5]       |      5.25 | https://openreview.net/forum?id=7Mq096hr9Y |
| LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents                                                             | [3, 6, 6, 6]       |      5.25 | https://openreview.net/forum?id=ADSxCpCu9s |
| Efficiency Pentathlon: A Standardized Benchmark for Efficiency Evaluation                                                                | [8, 5, 3, 5]       |      5.25 | https://openreview.net/forum?id=Qyp3Rni2g1 |
| Benchmarking Diffusion Based Text-Guided Image Editing Methods                                                                           | [6, 5, 5, 5]       |      5.25 | https://openreview.net/forum?id=nkCWKkSLyb |
| A  Multi-resolution Dataset of Self-consistent Cloth Drapes for Physics-based Upsampling                                                 | [5, 5, 6, 5]       |      5.25 | https://openreview.net/forum?id=aAhgJ1fQ4V |
| On the Tool Manipulation Capability of Open-sourced Large Language Models                                                                | [5, 5, 5, 6]       |      5.25 | https://openreview.net/forum?id=iShM3YolRY |
| G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural Networks                                                            | [5, 6, 5, 5]       |      5.25 | https://openreview.net/forum?id=iUD9FklwQf |
| Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning                                                                 | [6, 8, 3, 3, 6]    |      5.2  | https://openreview.net/forum?id=JnRStoIuTe |
| Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning                                                | [6, 6, 6, 5, 3]    |      5.2  | https://openreview.net/forum?id=VIEbRFp6s3 |
| ALMANACS: A Simulatability Benchmark for Language Model Explainability                                                                   | [8, 6, 3, 3]       |      5    | https://openreview.net/forum?id=KJzwUyryyl |
| ObjectNet Captions: Models are not superhuman captioners                                                                                 | [5, 5, 5, 5]       |      5    | https://openreview.net/forum?id=U17KoLrXE8 |
| VideoGLUE: Video General Understanding Evaluation of Foundation Models                                                                   | [6, 6, 3, 5]       |      5    | https://openreview.net/forum?id=q20O1J9ujh |
| GnnX-Bench: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking                                   | [3, 6, 6, 5]       |      5    | https://openreview.net/forum?id=VJvbOSXRUq |
| Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models                                    | [5, 3, 6, 6]       |      5    | https://openreview.net/forum?id=6bcAD6g688 |
| Multilingual Code Retrieval Without Paired Data: New Datasets and Benchmarks                                                             | [3, 5, 6, 6]       |      5    | https://openreview.net/forum?id=jwzm44fsJ8 |
| Semi-HyperGraph Benchmark: Enhancing Flexibility of Hypergraph Learning with Datasets and Benchmarks                                     | [5, 5, 5]          |      5    | https://openreview.net/forum?id=NX0eNGXezp |
| A Benchmark Study on Calibration                                                                                                         | [6, 3, 6]          |      5    | https://openreview.net/forum?id=GzNhzX9kVa |
| Adaptive Visual Scene Understanding: Incremental Scene Graph Generation                                                                  | [5, 5, 6, 3, 6]    |      5    | https://openreview.net/forum?id=3edHHvu5GX |
| CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment                      | [3, 6, 5, 6]       |      5    | https://openreview.net/forum?id=nMFSUjxMIl |
| BIRB: A Generalization Benchmark for Information Retrieval in Bioacoustics                                                               | [5, 5, 5, 5]       |      5    | https://openreview.net/forum?id=ybiwT2yP1c |
| MMBench: Is Your Multi-modal Model an All-around Player?                                                                                 | [6, 6, 3, 5]       |      5    | https://openreview.net/forum?id=BfMQIJ0nLc |
| MIMIC: Masked Image Modeling with Image Correspondences                                                                                  | [6, 8, 3, 3]       |      5    | https://openreview.net/forum?id=uhtQyRrTzY |
| IMP: Benchmarking Image Polysemy in Vision-Language Models                                                                               | [3, 5, 8, 5, 3]    |      4.8  | https://openreview.net/forum?id=RIbH5ekQpr |
| Robustness Evaluation of Proxy Models against Adversarial Optimization                                                                   | [5, 5, 6, 3]       |      4.75 | https://openreview.net/forum?id=4N7v4w2r3b |
| Programmatic Evaluation of Rule-Following Behavior                                                                                       | [3, 5, 6, 5]       |      4.75 | https://openreview.net/forum?id=ikqcUzUogm |
| ChatSearch: a Dataset and a Generative Retrieval Model for General Conversational Image Retrieval                                        | [6, 5, 5, 3]       |      4.75 | https://openreview.net/forum?id=0unbjYPmbC |
| ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks                              | [3, 5, 6, 5]       |      4.75 | https://openreview.net/forum?id=ZuYvrjh2od |
| FruitBin: A tunable large-scale dataset for advancing 6D Pose estimation in fruit bin picking automation                                 | [3, 3, 8, 5]       |      4.75 | https://openreview.net/forum?id=4IxtmklIym |
| Do Large Language Models Know about Facts?                                                                                               | [3, 5, 5, 6]       |      4.75 | https://openreview.net/forum?id=9OevMUdods |
| In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Induced Search                                 | [8, 3, 3, 5]       |      4.75 | https://openreview.net/forum?id=5KcFkhEj4x |
| RLP: A reinforcement learning benchmark for neural algorithmic reasoning                                                                 | [5, 3, 6, 5]       |      4.75 | https://openreview.net/forum?id=pYmQId95iR |
| PowerGraph: A power grid benchmark dataset for graph neural networks                                                                     | [3, 8, 3, 5]       |      4.75 | https://openreview.net/forum?id=fyCPspuM5L |
| FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things                                                            | [5, 5, 3, 6]       |      4.75 | https://openreview.net/forum?id=11WAKGH8uv |
| WEAR: An Outdoor Sports Dataset for Wearable and Egocentric Activity Recognition                                                         | [3, 6, 5, 5]       |      4.75 | https://openreview.net/forum?id=Nxn6vGgpI9 |
| M$^4$LE: A Multi-Ability Multi-Range Long Context Evaluation Benchmark for Large Language Models                                         | [3, 5, 6, 5]       |      4.75 | https://openreview.net/forum?id=IkIqzDI7ie |
| SelfClean: A Self-Supervised Data Cleaning Strategy                                                                                      | [6, 6, 1, 6]       |      4.75 | https://openreview.net/forum?id=cRbnZs2WY4 |
| Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and Toolkit                                                         | [5, 6, 5, 3]       |      4.75 | https://openreview.net/forum?id=3DPTnFokLp |
| ${\rm EFO}_k$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation                                                  | [5, 3, 6, 5]       |      4.75 | https://openreview.net/forum?id=xwZhyKynCB |
| DynaEval: A Dynamic Interaction-based Evaluation Framework for Assessing LLMs in Real-world Scenarios                                    | [3, 8, 5, 3]       |      4.75 | https://openreview.net/forum?id=f7PmO5boQ9 |
| xCodeEval: An Execution based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval | [5, 5, 3, 6]       |      4.75 | https://openreview.net/forum?id=wpTitXWGNO |
| RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models                                          | [5, 3, 6, 5]       |      4.75 | https://openreview.net/forum?id=i4ULDEeBss |
| FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs                                               | [3, 5, 5, 6]       |      4.75 | https://openreview.net/forum?id=DY6uhcv4Xm |
| MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models                                              | [3, 5, 3, 8]       |      4.75 | https://openreview.net/forum?id=a7eIuzEh2R |
| EGraFFBench: Evaluation of Equivariant Graph Neural Network Force Fields for Atomistic Simulations                                       | [3, 8, 3]          |      4.67 | https://openreview.net/forum?id=NvJxTjTQtq |
| Video-CSR: Complex Video Digest Creation for Visual-Language Models                                                                      | [6, 5, 3]          |      4.67 | https://openreview.net/forum?id=Vzn7c8SWbX |
| Critique Ability of Large Language Models                                                                                                | [6, 5, 3]          |      4.67 | https://openreview.net/forum?id=50P9TDPEsh |
| DEEP UNSUPERVISED DOMAIN ADAPTATION FOR TIME SERIES CLASSIFICATION: A BENCHMARK                                                          | [5, 3, 6]          |      4.67 | https://openreview.net/forum?id=xsts7MRLey |
| Structured Evaluation of Synthetic Tabular Data                                                                                          | [3, 6, 5]          |      4.67 | https://openreview.net/forum?id=YD0GQBOFFZ |
| Put on your detective hat: What’s wrong in this video?                                                                                   | [3, 6, 5]          |      4.67 | https://openreview.net/forum?id=Uj2Wjv0pMY |
| OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments                                                                   | [3, 5, 5, 5]       |      4.5  | https://openreview.net/forum?id=4PzxLPEGRn |
| How Far Have We Gone in Vulnerability Detection Using Large Language Model                                                               | [5, 3, 5, 5]       |      4.5  | https://openreview.net/forum?id=Q3GVrWRKuB |
| PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs                                                 | [5, 6, 1, 6]       |      4.5  | https://openreview.net/forum?id=ApjY32f3Xr |
| Loco3D: Indoor Multiuser Locomotion 3D Dataset                                                                                           | [5, 3, 5, 5]       |      4.5  | https://openreview.net/forum?id=5eLgTLusaR |
| A Symbolic Framework for Evaluating Mathematical Reasoning with Transformers                                                             | [6, 3, 3, 6]       |      4.5  | https://openreview.net/forum?id=7n8RzGQKnR |
| The Unreasonable Effectiveness of Pretraining in Graph OOD                                                                               | [3, 5, 5, 5]       |      4.5  | https://openreview.net/forum?id=7Jer2DQt9V |
| What Makes ImageNet Look Unlike LAION                                                                                                    | [5, 5, 3, 5]       |      4.5  | https://openreview.net/forum?id=TMYxJIcdgS |
| Mo' Data Mo' Problems: How Data Composition Compromises Scaling Properties                                                               | [6, 6, 3, 3]       |      4.5  | https://openreview.net/forum?id=j5EbZEyK9I |
| CoDBench: A Critical Evaluation of Data-driven Models for Continuous Dynamical Systems                                                   | [6, 6, 3, 3]       |      4.5  | https://openreview.net/forum?id=S7ZQgHfW3w |
| DivKnowQA: Verifying the Reasoning Ability of LLM Through Open-Domain Question Answering Over Knowledge Base and Text                    | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=9AnR2z7iNL |
| Pushing the Limits of Pre-training for Time Series Forecasting in the CloudOps Domain                                                    | [3, 5, 5]          |      4.33 | https://openreview.net/forum?id=ZkEsEFFUyo |
| Unified Long-Term Time-Series Forecasting  Benchmark                                                                                     | [3, 5, 5]          |      4.33 | https://openreview.net/forum?id=3rBu7dR7rm |
| Who SAID that? Benchmarking Social Media AI Detection                                                                                    | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=THtX863Io2 |
| Deep-Learning Approaches for Optimized Web Accessibility: Correcting Violations and Enhancing User Experience                            | [5, 5, 3]          |      4.33 | https://openreview.net/forum?id=gdNruOMSwc |
| PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations                                                             | [5, 1, 6, 5]       |      4.25 | https://openreview.net/forum?id=CbmAtAmQla |
| SCALE: Scaling up the Complexity for Advanced Language Model Evaluation                                                                  | [6, 5, 3, 3]       |      4.25 | https://openreview.net/forum?id=aLXRYfIUUd |
| Disco-Bench: A Context-Aware Evaluation Benchmark for Language Modelling                                                                 | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=GAXedKmbFZ |
| Large Language Model Routing with Benchmark Datasets                                                                                     | [3, 6, 3, 5]       |      4.25 | https://openreview.net/forum?id=LyNsMNNLjY |
| Quantifying Zero-shot Coordination Capability with Behavior Preferring Partners                                                          | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=wTRpjTO3F7 |
| TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications                                               | [5, 3, 6, 3]       |      4.25 | https://openreview.net/forum?id=fTEPeQ00VM |
| Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection                                                                    | [3, 3, 5, 6]       |      4.25 | https://openreview.net/forum?id=RxhOEngX8s |
| BMAD: Benchmarks for Medical Anomaly Detection                                                                                           | [6, 5, 3, 3]       |      4.25 | https://openreview.net/forum?id=2SuA42Mq1c |
| BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks                                                                  | [3, 5, 6, 3]       |      4.25 | https://openreview.net/forum?id=uKB4cFNQFg |
| D5RL: Diverse Datasets for Data-Driven Deep Reinforcement Learning                                                                       | [5, 5, 6, 1]       |      4.25 | https://openreview.net/forum?id=Aj1wftldeR |
| XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making                                                                | [5, 3, 6, 3]       |      4.25 | https://openreview.net/forum?id=Ba5KGabRe8 |
| HeroLT: Benchmarking Heterogeneous Long-Tailed Learning                                                                                  | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=eADuHv62J5 |
| APBench: A Unified Benchmark for Availability Poisoning Attacks and Defenses                                                             | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=1VcKvdYbUM |
| Can long-context large language models understand long contexts?                                                                         | [8, 3, 3, 3]       |      4.25 | https://openreview.net/forum?id=rtzUW1FU3H |
| Assessing Large Language Models on Climate Information                                                                                   | [3, 3, 3, 8]       |      4.25 | https://openreview.net/forum?id=IAWIgFT71j |
| Beyond the Benchmark: Detecting Diverse Anomalies in Videos                                                                              | [6, 3, 5, 3]       |      4.25 | https://openreview.net/forum?id=WnEnU2K3Rb |
| BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for Graph Continual Learning                                           | [3, 6, 3, 5]       |      4.25 | https://openreview.net/forum?id=W9DxKDCVnr |
| Data Curation for Large Scale Detection Pretraining                                                                                      | [3, 5, 5, 3]       |      4    | https://openreview.net/forum?id=cj4J7aaKQp |
| GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond                                | [3, 3, 6]          |      4    | https://openreview.net/forum?id=f77r0cBc4l |
| 3D Dense Captioning beyond Nouns: A Middleware for Autonomous Driving                                                                    | [3, 3, 6]          |      4    | https://openreview.net/forum?id=8T7m27VC3S |
| Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-Temporal Reasoning                             | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=fe8CzLTMG1 |
| StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code                                                    | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=o6XxdC4QsX |
| Battle of the Wordsmiths: Comparing ChatGPT, GPT-4, Claude, and Bard                                                                     | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=sTr11zs10n |
| HHD-Ethiopic: A Historical Handwritten Dataset for Ethiopic OCR with Baseline Models and Human-level Performance                         | [5, 5, 3, 3]       |      4    | https://openreview.net/forum?id=L7KDMsqWl9 |
| Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective                                                     | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=s6X3s3rBPW |
| PIANO PERFORMANCE EVALUATION DATASET WITH MULTI-LEVEL PERCEPTUAL FEATURES                                                                | [3, 6, 3, 6, 3, 3] |      4    | https://openreview.net/forum?id=5F0WDt9CjA |
| FHA-Kitchens: A Novel Dataset for Fine-Grained Hand Action Recognition in Kitchen Scenes                                                 | [3, 5, 3, 5]       |      4    | https://openreview.net/forum?id=otoggKnn0A |
| TeG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Task Design                                                      | [3, 3, 5, 5]       |      4    | https://openreview.net/forum?id=KzMMv0OygD |
| CodeComplex: A Time-complexity Dataset for Multi-language Source Codes                                                                   | [5, 5, 3, 3]       |      4    | https://openreview.net/forum?id=8tGu1pNUnN |
| RL4CO: a Unified Reinforcement Learning for Combinatorial Optimization Library                                                           | [3, 5, 3, 5]       |      4    | https://openreview.net/forum?id=tgjGR7eY5H |
| LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models                                                          | [3, 5, 3, 5]       |      4    | https://openreview.net/forum?id=8cNMMrWRbZ |
| ContextNER: Contextual Phrase Generation at Scale                                                                                        | [6, 3, 3]          |      4    | https://openreview.net/forum?id=4iQuByhNie |
| Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs                                                   | [5, 6, 3, 1]       |      3.75 | https://openreview.net/forum?id=evk6pPJqMy |
| Benchmarks for Reinforcement Learning with Biased Offline Data and Imperfect Simulators                                                  | [6, 3, 3, 3]       |      3.75 | https://openreview.net/forum?id=uwjDyJfe3m |
| Benchmarking Multivariate Time Series Anomaly Detection with Large-Scale Real-World Datasets                                             | [6, 3, 3, 3]       |      3.75 | https://openreview.net/forum?id=sFbTM7D1hO |
| Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena                        | [3, 3, 3, 6]       |      3.75 | https://openreview.net/forum?id=crMMk4I8Wy |
| ToolTalk: Evaluating Tool Usage in a Conversational Setting                                                                              | [3, 3, 6, 3]       |      3.75 | https://openreview.net/forum?id=iTddgL0lTQ |
| 3D Human Reconstruction in the Wild with Synthetic Data Using Generative Models                                                          | [3, 6, 3, 3]       |      3.75 | https://openreview.net/forum?id=TCGUnoiaWP |
| DER-Solomon: A Large Number of CVRPTW Instances Generated Based on the Solomon Benchmark Distribution                                    | [3, 6, 3, 3]       |      3.75 | https://openreview.net/forum?id=HTH3HnJeRC |
| CNNGEN: A GENERATOR AND BENCHMARK FOR SUSTAINABLE CONVOLUTIONAL NEURAL NETWORK SEARCH                                                    | [5, 3, 3]          |      3.67 | https://openreview.net/forum?id=HgndgAbBcR |
| Benchmarks and Custom Package for Electrical Load Forecasting                                                                            | [5, 3, 3]          |      3.67 | https://openreview.net/forum?id=gjB7qqPJbv |
| Beyond Shortest-Paths: A Benchmark for Reinforcement Learning on Traffic Engineering                                                     | [3, 3, 6, 3, 3]    |      3.6  | https://openreview.net/forum?id=4jBL79L5QS |
| Semi-supervised Long-tailed Recognition using Alternate Sampling                                                                         | [3, 5, 3, 3]       |      3.5  | https://openreview.net/forum?id=kaZAKvjLro |
| Dissecting Zero-Shot Visual Reasoning Capabilities in Vision and Language Models                                                         | [3, 3, 5, 3]       |      3.5  | https://openreview.net/forum?id=UndmcWatBN |
| Continual Knowledge Graph Link Prediction: Beyond Experience Replay                                                                      | [3, 3, 3, 5]       |      3.5  | https://openreview.net/forum?id=gP9TWGHtGM |
| REVO-LION: Evaluating and Refining Vision-Language Instruction Tuning Datasets                                                           | [3, 3, 5, 3]       |      3.5  | https://openreview.net/forum?id=LixtB4TYY2 |
| All Languages Matter: On the Multilingual Safety of Large Language Models                                                                | [3, 3, 3, 5]       |      3.5  | https://openreview.net/forum?id=JL42j1BL5h |
| JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning                                                          | [3, 5, 3, 3]       |      3.5  | https://openreview.net/forum?id=aAEBTnTGo3 |
| UGSL: A Unified Framework for Benchmarking Graph Structure Learning                                                                      | [3, 3, 5, 3]       |      3.5  | https://openreview.net/forum?id=DLfdJEuXkR |
| A Conceptual Framework for Analyzing Social Representation in Unstructured Data                                                          | [3, 3, 3, 3, 5]    |      3.4  | https://openreview.net/forum?id=s3rjenIOfx |
| Regulating the level of manipulation in text augmentation with systematic adjustment and advanced sentence-embedding                     | [3, 6, 1, 3]       |      3.25 | https://openreview.net/forum?id=TkP2RtR4hr |
| CropNet: An Open Large-Scale Dataset with Multiple Modalities for Climate Change-aware Crop Yield Predictions                            | [3, 6, 1, 3]       |      3.25 | https://openreview.net/forum?id=lzpHNyhIbr |
| TabGraphs: new benchmark and insights for learning on graphs with tabular features                                                       | [1, 3, 3, 6]       |      3.25 | https://openreview.net/forum?id=Ue93J8VV3W |
| Structure-Rich Text Benchmark for Knowledge Inference Evaluation                                                                         | [6, 3, 1, 3]       |      3.25 | https://openreview.net/forum?id=ly10tMV6cD |
| Large Language Models as Rational Players in Competitive Economics Games                                                                 | [3, 3, 3, 3, 3]    |      3    | https://openreview.net/forum?id=NMPLBbjYFq |
| Can General-Purpose Language Models Emulate a General-Purpose Computer In-Context?                                                       | [3, 3, 3, 3]       |      3    | https://openreview.net/forum?id=aX4fOLHrXT |
| INCYDE: A large scale cyclone detection and intensity estimation dataset using satellite infrared imagery                                | [5, 1, 3]          |      3    | https://openreview.net/forum?id=anG8cNYQAs |
| MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things                                                           | [1, 3, 5]          |      3    | https://openreview.net/forum?id=eS5zjXvxf8 |
| Building a Special Representation for the Chinese Ancient Buildings in Diffusion models.                                                 | [3, 5, 1]          |      3    | https://openreview.net/forum?id=kCnLHHtk1y |
| TPA-Gen: A Multi-modal Data Generative Method for Text and Physics-based Animation                                                       | [3, 5, 1]          |      3    | https://openreview.net/forum?id=G7M3f3Ditm |
| GRADSIMCORE: GRADIENT SIMILARITY BASED REPRESENTATIVE INSTANCES AS CORESET                                                               | [1, 3, 3, 3]       |      2.5  | https://openreview.net/forum?id=cHy00K3Och |
| Tracking Cognitive Development of Large Language Models                                                                                  | [3, 3, 1, 3]       |      2.5  | https://openreview.net/forum?id=fI6TkT050a |
| LST-Bench:A Benchmark for long sequence time-series forecasting Task                                                                     | [1, 3, 3, 3]       |      2.5  | https://openreview.net/forum?id=2wwPG1wpsu |